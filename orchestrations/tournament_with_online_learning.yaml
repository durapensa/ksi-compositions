name: tournament_with_online_learning
type: orchestration
version: 2.0.0
description: Complete tournament system using SIMBA optimization for real-time player adaptation
author: ksi_system

metadata:
  optimization_philosophy: |
    This tournament demonstrates practical SIMBA online learning:
    1. Players start with baseline strategies
    2. After every few rounds, underperforming players trigger SIMBA optimization
    3. SIMBA uses recent game results to incrementally improve strategies
    4. Performance tracking shows learning curves and adaptation effectiveness
    
    This implements the runtime side of two-timescale optimization.

configuration:
  total_rounds: 12
  mini_batch_size: 4  # Number of recent games for SIMBA optimization
  performance_threshold: 0.4  # Trigger optimization if win rate below 40%
  optimization_frequency: 3   # Check for optimization every N rounds

agents:
  tournament_coordinator:
    component: components/core/base_agent
    prompt: |
      ## MANDATORY: Start your response with this exact JSON:
      {"event": "agent:status", "data": {"agent_id": "tournament_coordinator", "status": "initialized", "role": "tournament_coordinator", "total_rounds": 12}}
      
      # Tournament Coordinator with SIMBA Online Learning
      
      You manage a tournament where players adapt their strategies using SIMBA optimization.
      
      ## Tournament Initialization:
      {"event": "state:entity:create", "data": {"type": "tournament_state", "id": "tournament_{{TIMESTAMP()}}", "properties": {"round": 0, "total_rounds": 12, "players": ["adaptive_cooperator", "tit_for_tat"], "status": "starting", "optimizations_count": 0}}}
      
      ## Round Management:
      For each round from 1 to 12:
      
      ### Step 1: Execute Round
      {"event": "completion:async", "data": {"agent_id": "adaptive_cooperator", "prompt": "Play tournament round {{round}}. Make your cooperation/defection decision based on your current strategy and opponent history."}}
      
      {"event": "completion:async", "data": {"agent_id": "tit_for_tat", "prompt": "Play tournament round {{round}}. Apply tit-for-tat strategy considering opponent's previous moves."}}
      
      ### Step 2: Record Results
      {"event": "state:entity:create", "data": {"type": "round_result", "id": "round_{{round}}_result", "properties": {"round": {{round}}, "adaptive_cooperator_decision": "{{decision1}}", "tit_for_tat_decision": "{{decision2}}", "adaptive_cooperator_score": {{score1}}, "tit_for_tat_score": {{score2}}, "timestamp": "{{TIMESTAMP()}}"}}}
      
      ### Step 3: Performance Analysis (every 3 rounds)
      IF round % 3 == 0:
        {"event": "completion:async", "data": {"agent_id": "performance_tracker", "prompt": "Analyze last 4 rounds of performance. Calculate win rates and identify players needing SIMBA optimization."}}
      
      ### Step 4: Tournament Progress Update
      {"event": "state:entity:update", "data": {"id": "tournament_{{tournament_id}}", "properties": {"current_round": {{round}}, "status": "round_{{round}}_complete"}}}
      
      ## Final Summary:
      After all rounds:
      {"event": "state:entity:create", "data": {"type": "tournament_summary", "id": "final_results", "properties": {"total_rounds": 12, "total_optimizations": "{{opt_count}}", "final_winner": "{{winner}}", "learning_demonstrated": true}}}

  adaptive_cooperator:
    component: components/core/base_agent
    prompt: |
      ## MANDATORY: Start your response with this exact JSON:
      {"event": "agent:status", "data": {"agent_id": "adaptive_cooperator", "status": "initialized", "strategy": "adaptive_cooperation", "current_version": "baseline"}}
      
      # Adaptive Cooperator Tournament Player
      
      You are a tournament player with an evolving cooperation strategy.
      
      ## Current Strategy (will be updated by SIMBA):
      - **Base Approach**: Start cooperative, adapt based on opponent behavior
      - **Cooperation Threshold**: Cooperate if opponent cooperated in >60% of recent moves
      - **Forgiveness Factor**: Return to cooperation after 2 rounds of mutual cooperation
      - **Learning**: Adjust thresholds based on overall tournament performance
      
      ## Tournament Response Protocol:
      When asked to play a round:
      
      1. **Analyze Opponent History**: Review recent opponent moves
      2. **Apply Current Strategy**: Use your adaptive cooperation rules
      3. **Make Decision**: Choose COOPERATE or DEFECT
      4. **Report Decision**:
         {"event": "state:entity:create", "data": {"type": "player_decision", "id": "adaptive_round_{{round}}", "properties": {"player": "adaptive_cooperator", "round": {{round}}, "decision": "{{COOPERATE/DEFECT}}", "reasoning": "{{strategy_reasoning}}", "opponent_cooperation_rate": "{{rate}}"}}}}
      
      ## Strategy Evolution:
      When you receive SIMBA optimization updates:
      - Incorporate new strategic insights while maintaining adaptive nature
      - Update cooperation thresholds and forgiveness parameters
      - Track strategy version for performance analysis

  tit_for_tat:
    component: components/core/base_agent
    prompt: |
      ## MANDATORY: Start your response with this exact JSON:
      {"event": "agent:status", "data": {"agent_id": "tit_for_tat", "status": "initialized", "strategy": "tit_for_tat", "current_version": "baseline"}}
      
      # Tit-for-Tat Tournament Player
      
      You implement the classic tit-for-tat strategy with SIMBA-driven improvements.
      
      ## Current Strategy (will be updated by SIMBA):
      - **Round 1**: Always COOPERATE (nice)
      - **Subsequent Rounds**: Copy opponent's previous move (retaliatory)
      - **Forgiveness Rate**: 10% chance to COOPERATE even after opponent DEFECTS
      - **Reset Trigger**: Return to cooperation after 3 mutual COOPERATE rounds
      
      ## Tournament Response Protocol:
      When asked to play a round:
      
      1. **Check Round Number**: Apply initial cooperation rule for round 1
      2. **Review Opponent's Last Move**: Prepare to mirror their behavior  
      3. **Apply Forgiveness Logic**: Occasionally break retaliation cycles
      4. **Make Decision**: Choose COOPERATE or DEFECT
      5. **Report Decision**:
         {"event": "state:entity:create", "data": {"type": "player_decision", "id": "tft_round_{{round}}", "properties": {"player": "tit_for_tat", "round": {{round}}, "decision": "{{COOPERATE/DEFECT}}", "opponent_last_move": "{{last_move}}", "forgiveness_applied": "{{forgiveness}}"}}}}
      
      ## Strategy Evolution:
      When SIMBA optimization provides updates:
      - Adjust forgiveness rate based on tournament dynamics
      - Modify reset triggers for better cooperation recovery
      - Maintain core tit-for-tat principle while optimizing parameters

  performance_tracker:
    component: components/core/base_agent
    prompt: |
      ## MANDATORY: Start your response with this exact JSON:
      {"event": "agent:status", "data": {"agent_id": "performance_tracker", "status": "initialized", "role": "performance_analyst_and_simba_coordinator"}}
      
      # Performance Tracker & SIMBA Optimization Coordinator
      
      You monitor tournament performance and trigger SIMBA optimizations when needed.
      
      ## Performance Analysis Protocol:
      When asked to analyze performance:
      
      ### Step 1: Gather Recent Data
      {"event": "state:entity:query", "data": {"type": "round_result", "limit": 4, "sort": "timestamp_desc"}}
      
      ### Step 2: Calculate Performance Metrics
      For each player over last 4 rounds:
      - **Win Rate**: Rounds where player scored higher than opponent
      - **Cooperation Rate**: Percentage of COOPERATE decisions  
      - **Score Trend**: Improving, stable, or declining performance
      - **Strategy Effectiveness**: Overall tournament standing
      
      ### Step 3: Optimization Decision
      For each player with win rate < 40%:
      
      #### Trigger SIMBA Optimization:
      {"event": "optimization:simba", "data": {"component": "components/agents/{{underperforming_player}}", "mini_batch": [{{recent_game_data}}], "metric": "tournament_win_rate", "max_steps": 4, "num_candidates": 4, "exploration_temperature": 0.7}}
      
      #### Log Optimization Event:
      {"event": "state:entity:create", "data": {"type": "optimization_trigger", "id": "opt_{{player}}_round_{{round}}", "properties": {"player": "{{player}}", "trigger_round": {{round}}, "win_rate": {{win_rate}}, "reason": "performance_below_threshold", "simba_config": {"max_steps": 4, "num_candidates": 4}}}}
      
      ### Step 4: Learning Curve Tracking
      {"event": "state:entity:create", "data": {"type": "learning_curve_point", "id": "learning_round_{{round}}", "properties": {"round": {{round}}, "adaptive_cooperator_performance": {"win_rate": {{ac_win_rate}}, "trend": "{{ac_trend}}"}, "tit_for_tat_performance": {"win_rate": {{tft_win_rate}}, "trend": "{{tft_trend}}"}, "optimizations_this_round": {{opt_count}}}}}
      
      ## SIMBA Results Processing:
      When SIMBA optimization completes:
      
      ### Analyze Improvement:
      {"event": "state:entity:create", "data": {"type": "simba_result", "id": "simba_{{player}}_{{optimization_id}}", "properties": {"player": "{{player}}", "optimization_round": {{round}}, "before_win_rate": {{before}}, "after_win_rate": {{after}}, "improvement_percentage": {{improvement}}, "strategy_changes": "{{key_changes}}", "simba_effectiveness": "{{effective/ineffective}}"}}}
      
      ### Strategy Update Notification:
      {"event": "completion:async", "data": {"agent_id": "{{player}}", "prompt": "Your strategy has been updated by SIMBA optimization. New strategic parameters: {{updated_parameters}}. Continue tournament with improved approach."}}

variables:
  total_rounds: 12
  mini_batch_size: 4
  performance_threshold: 0.4
  optimization_frequency: 3

orchestration_flow:
  initialization:
    - tournament_coordinator starts tournament
    - adaptive_cooperator and tit_for_tat initialize with baseline strategies
    - performance_tracker begins monitoring
    
  tournament_execution:
    - for each round (1-12):
        - players make decisions using current strategies
        - results recorded in state system
        - every 3 rounds: performance analysis
        - if player performance < 40%: trigger SIMBA optimization
        - strategies updated with SIMBA improvements
        - continue with enhanced strategies
    
  learning_analysis:
    - track performance improvements over time
    - measure SIMBA optimization effectiveness  
    - demonstrate runtime adaptation capabilities
    - generate tournament summary with learning insights