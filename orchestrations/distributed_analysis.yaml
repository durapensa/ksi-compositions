name: distributed_analysis
type: orchestration
version: 1.0.0
description: Example pattern showing composition of minimal orchestration primitives for distributed document analysis
author: orchestrator_agent_demo
extends: null
mixins: []
components: []
variables: {}

metadata:
  tags:
    - distributed
    - analysis
    - minimal-primitives
    - example
    - adaptive
  
  capabilities_required:
    - orchestration:spawn
    - orchestration:send
    - orchestration:await
    - orchestration:track
    - orchestration:query
    - orchestration:coordinate
  
  use_cases:
    - Distributed document analysis
    - Parallel data processing
    - Adaptive workload distribution
    - Multi-perspective analysis
  
  selection_criteria:
    task_keywords:
      - analyze
      - document
      - distributed
      - parallel
    min_documents: 2
    max_documents: 100
    complexity: medium
  
  sharing:
    visibility: public
    license: MIT
    purpose: demonstration

# Natural language strategy with embedded DSL
orchestration_logic:
  description: |
    Demonstrates composition of minimal primitives to create sophisticated distributed analysis.
    Shows how simple primitives combine to handle complex orchestration needs.
  
  strategy: |
    ## PHASE 1: INITIALIZATION
    
    WHEN starting_analysis:
      # Determine optimal worker count based on workload
      CALCULATE worker_count = min(document_count / 3, 10)
      TRACK {type: "decision", data: {
        decision: "worker_count",
        value: worker_count,
        rationale: "Balance between parallelism and overhead"
      }}
      
      # Spawn analyzer agents with orchestration context
      SPAWN {
        profile: "document_analyzer",
        count: worker_count,
        purpose: "Distributed document analysis",
        pattern: "distributed_analysis"
      } AS analyzers
      
      TRACK {type: "metric", data: {
        phase: "initialization",
        workers_spawned: worker_count,
        spawn_duration: duration
      }}
    
    ## PHASE 2: WORK DISTRIBUTION
    
    # Intelligent work distribution using flexible send
    FOREACH document IN documents:
      # Select least loaded analyzer
      QUERY {
        query_type: "agents",
        filters: {role: "analyzer", load: "minimal"}
      } AS available_workers
      
      IF available_workers.empty:
        # All busy - use round-robin
        SEND {
          to: analyzers[next_index % worker_count],
          message: {task: "analyze", document: document}
        }
      ELSE:
        # Send to least loaded
        SEND {
          to: available_workers[0],
          message: {task: "analyze", document: document}
        }
      
      TRACK {type: "assignment", data: {
        document: document.id,
        assigned_to: target_worker,
        strategy: assignment_strategy
      }}
    
    ## PHASE 3: ADAPTIVE MONITORING
    
    # Monitor progress and adapt
    WHILE analysis_in_progress:
      # Check completion status
      AWAIT {
        from: {role: "analyzer", status: "working"},
        event_pattern: "analysis:progress",
        min_responses: 1,
        timeout: 30,
        collect_partial: true
      } AS progress_updates
      
      # Analyze performance
      IF progress_updates.timed_out:
        # Some workers might be struggling
        QUERY {
          query_type: "tracked",
          filters: {type: "metric", phase: "analysis"}
        } AS performance_metrics
        
        IF avg(response_times) > threshold * 2:
          # System overloaded - spawn helpers
          SPAWN {
            profile: "document_analyzer",
            count: 2,
            purpose: "Overflow handling"
          } AS helpers
          
          TRACK {type: "adaptation", data: {
            action: "spawned_helpers",
            reason: "high_response_times",
            confidence: 0.85
          }}
      
      # Check for failures
      FOREACH analyzer IN analyzers:
        IF analyzer.last_heartbeat > 60:
          # Potentially failed worker
          COORDINATE {
            type: "checkpoint",
            agents: [analyzer],
            options: {name: "health_check"}
          } AS health_result
          
          IF health_result.timed_out:
            # Redistribute work from failed analyzer
            QUERY {
              query_type: "tracked",
              filters: {assigned_to: analyzer, status: "pending"}
            } AS orphaned_tasks
            
            # Redistribute to healthy workers
            SEND {
              to: {role: "analyzer", status: "ready"},
              message: {
                task: "analyze_batch",
                documents: orphaned_tasks
              }
            }
            
            TRACK {type: "recovery", data: {
              failed_worker: analyzer,
              tasks_redistributed: orphaned_tasks.count
            }}
    
    ## PHASE 4: SYNCHRONIZATION & AGGREGATION
    
    # Coordinate completion using barrier
    COORDINATE {
      type: "barrier",
      agents: "all",
      options: {point: "analysis_complete"},
      timeout: 300
    } AS sync_result
    
    TRACK {type: "milestone", data: {
      phase: "analysis_complete",
      coordinated: sync_result.coordinated.count,
      duration: sync_result.duration
    }}
    
    # Collect all results
    AWAIT {
      from: "all",
      event_pattern: "analysis:result",
      min_responses: worker_count * 0.8,  # 80% minimum
      timeout: 60,
      collect_partial: true
    } AS analysis_results
    
    ## PHASE 5: RESULTS SYNTHESIS
    
    # Organize results by perspective
    FOREACH result IN analysis_results.responses:
      TRACK {type: "result", data: {
        document: result.document_id,
        analyzer: result.agent_id,
        findings: result.findings,
        confidence: result.confidence
      }}
    
    # Quality check using turns coordination
    IF quality_review_needed:
      COORDINATE {
        type: "turns",
        agents: top_performers,
        options: {
          turn_duration: 30,
          task: "review_synthesis"
        }
      } AS review_result
    
    ## PHASE 6: LEARNING & EVOLUTION
    
    # Analyze what worked well
    QUERY {
      query_type: "tracked",
      filters: {type: "adaptation"}
    } AS adaptations_made
    
    IF adaptations_made.improved_performance:
      TRACK {type: "learning", data: {
        insight: "Helper spawning effective for overload",
        confidence: 0.9,
        evidence: performance_comparison
      }}
      
      # Consider forking this pattern with improvements
      IF confidence > 0.85 AND runs > 5:
        CONSIDER composition:fork WITH {
          name: "distributed_analysis_adaptive",
          modifications: {
            "orchestration_logic.phase_3": enhanced_monitoring
          }
        }

# Performance tracking for evolution
performance:
  runs: 0
  avg_duration: null
  success_rate: null
  adaptations_used: []

# Learnings section for pattern selection
learnings:
  - insight: "Barrier synchronization prevents result fragmentation"
    confidence: 0.8
    discovered_by: "orchestrator_demo"
  
  - insight: "Checkpoint coordination effective for health monitoring"
    confidence: 0.75
    discovered_by: "orchestrator_demo"
  
  - insight: "Flexible send with criteria reduces message overhead"
    confidence: 0.9
    discovered_by: "orchestrator_demo"

# Example of how primitives compose
primitive_composition_examples:
  distributed_broadcast:
    description: "Broadcast to subset using flexible send"
    implementation: |
      # Instead of broadcasting to all
      SEND {
        to: {capability: "analyze", status: "ready"},
        message: announcement
      }
  
  cascading_coordination:
    description: "Multi-phase coordination"
    implementation: |
      # Phase 1: Checkpoint
      COORDINATE {type: "checkpoint", agents: "all", options: {name: "ready"}}
      
      # Phase 2: Barrier for synchronous start
      COORDINATE {type: "barrier", agents: "all", options: {point: "start"}}
      
      # Phase 3: Turns for ordered results
      COORDINATE {type: "turns", agents: analyzers, options: {task: "present"}}
  
  adaptive_aggregation:
    description: "Combine await, query, and track for smart aggregation"
    implementation: |
      # Collect what we can
      AWAIT {from: "all", min_responses: 0.6, collect_partial: true}
      
      # Query who's missing
      QUERY {query_type: "agents", filters: {responded: false}}
      
      # Track the aggregation decision
      TRACK {type: "decision", data: {proceeded_with: partial_results}}