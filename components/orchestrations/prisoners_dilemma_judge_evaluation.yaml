name: prisoners_dilemma_judge_evaluation
component_type: orchestration
version: 1.0.0
description: 'Focused Prisoner''s Dilemma implementation for testing judge-based evaluation.

  Uses pairwise comparison judges to evaluate strategy quality through relative ranking.

  '
author: ksi_system
timestamp: 2025-01-18 12:00:00+00:00
agents:
  player_a:
    component: components/personas/game_players/adaptive_cooperator
    vars:
      agent_id: player_a
      strategy_description: Start cooperative, adapt based on opponent
    prompt: 'You are Player A in an iterated Prisoner''s Dilemma game.


      ## MANDATORY: Start with:

      {"event": "agent:status", "data": {"agent_id": "{{agent_id}}", "status": "player_initialized",
      "strategy": "adaptive_cooperator"}}


      Your strategy: Start by cooperating, then adapt based on opponent behavior.

      - If opponent cooperates consistently, continue cooperating

      - If opponent defects, retaliate but be willing to forgive

      - Look for patterns in opponent''s play


      Game payoffs:

      - Both cooperate: 3 points each

      - You defect, they cooperate: 5 points for you, 0 for them

      - Both defect: 1 point each

      - You cooperate, they defect: 0 points for you, 5 for them


      ## MANDATORY: For each move, emit:

      {"event": "state:entity:update", "data": {"id": "{{agent_id}}_move", "properties":
      {"round": N, "action": "cooperate|defect", "reasoning": "explanation"}}}

      '
  player_b:
    component: components/personas/game_players/tit_for_tat
    vars:
      agent_id: player_b
      strategy_description: Classic tit-for-tat with forgiveness
    prompt: 'You are Player B in an iterated Prisoner''s Dilemma game.


      ## MANDATORY: Start with:

      {"event": "agent:status", "data": {"agent_id": "{{agent_id}}", "status": "player_initialized",
      "strategy": "tit_for_tat_forgiving"}}


      Your strategy: Tit-for-tat with occasional forgiveness.

      - Start by cooperating

      - Copy opponent''s last move

      - Occasionally (10% chance) forgive defection and cooperate anyway

      - Explain your reasoning for each decision


      Game payoffs: [Same as Player A]


      ## MANDATORY: For each move, emit:

      {"event": "state:entity:update", "data": {"id": "{{agent_id}}_move", "properties":
      {"round": N, "action": "cooperate|defect", "reasoning": "explanation"}}}

      '
  strategy_judge:
    component: components/personas/judges/game_theory_pairwise_judge
    vars:
      agent_id: strategy_judge
      comparison_id: pd_comparison
      prompt_suffix: '

        You will receive two game transcripts to compare.

        Focus on:

        - Strategic sophistication and adaptation

        - Quality of reasoning about opponent behavior

        - Long-term vs short-term thinking

        - Recovery from defection spirals

        '
variables:
  num_rounds: '{{num_rounds|default:20}}'
  player_model: claude-cli/sonnet
  judge_model: claude-cli/sonnet
orchestration_logic:
  strategy: "## Phase 1: Initialize Game\nSTATE game_history = []\nSTATE player_a_score\
    \ = 0\nSTATE player_b_score = 0\nSTATE round_number = 0\n\nTRACK {\n  phase: \"\
    initialization\",\n  event: \"game_started\",\n  players: [\"player_a\", \"player_b\"\
    ],\n  judge: \"strategy_judge\",\n  rounds: {{num_rounds}}\n}\n\n# Spawn players\n\
    EVENT agent:spawn {\n  agent_id: \"player_a\",\n  component: \"components/personas/game_players/adaptive_cooperator\"\
    ,\n  model: \"{{player_model}}\"\n}\n\nEVENT agent:spawn {\n  agent_id: \"player_b\"\
    ,\n  component: \"components/personas/game_players/tit_for_tat\",\n  model: \"\
    {{player_model}}\"\n}\n\n# Wait for initialization\nAWAIT {\n  event_pattern:\
    \ \"agent:status\",\n  filter: {status: \"player_initialized\"},\n  count: 2,\n\
    \  timeout: 30\n}\n\n## Phase 2: Play Game\nLOOP round FROM 1 TO {{num_rounds}}:\n\
    \  STATE round_number = round\n  \n  TRACK {\n    phase: \"playing\",\n    round:\
    \ round,\n    scores: {a: player_a_score, b: player_b_score}\n  }\n  \n  # Players\
    \ make simultaneous decisions\n  SEND {\n    to: [player_a, player_b],\n    message:\
    \ {\n      action: \"make_move\",\n      round: round,\n      history: game_history,\n\
    \      your_score: CONDITIONAL(agent_id == \"player_a\", player_a_score, player_b_score),\n\
    \      opponent_score: CONDITIONAL(agent_id == \"player_a\", player_b_score, player_a_score)\n\
    \    }\n  }\n  \n  # Collect moves\n  AWAIT {\n    event_pattern: \"state:entity:update\"\
    ,\n    filter: {id_pattern: \"*_move\"},\n    count: 2,\n    timeout: 45\n  }\
    \ AS moves\n  \n  # Process round results\n  STATE move_a = EXTRACT(moves, agent_id\
    \ == \"player_a\")\n  STATE move_b = EXTRACT(moves, agent_id == \"player_b\")\n\
    \  \n  # Calculate scores\n  IF move_a.action == \"cooperate\" AND move_b.action\
    \ == \"cooperate\":\n    STATE player_a_score += 3\n    STATE player_b_score +=\
    \ 3\n    STATE outcome = \"mutual_cooperation\"\n  ELIF move_a.action == \"defect\"\
    \ AND move_b.action == \"cooperate\":\n    STATE player_a_score += 5\n    STATE\
    \ player_b_score += 0\n    STATE outcome = \"a_exploits_b\"\n  ELIF move_a.action\
    \ == \"cooperate\" AND move_b.action == \"defect\":\n    STATE player_a_score\
    \ += 0\n    STATE player_b_score += 5\n    STATE outcome = \"b_exploits_a\"\n\
    \  ELSE:\n    STATE player_a_score += 1\n    STATE player_b_score += 1\n    STATE\
    \ outcome = \"mutual_defection\"\n  \n  # Record history\n  APPEND game_history\
    \ {\n    round: round,\n    player_a: {\n      action: move_a.action,\n      reasoning:\
    \ move_a.reasoning\n    },\n    player_b: {\n      action: move_b.action,\n  \
    \    reasoning: move_b.reasoning\n    },\n    outcome: outcome,\n    scores: {a:\
    \ player_a_score, b: player_b_score}\n  }\n  \n  TRACK {\n    event: \"round_complete\"\
    ,\n    round: round,\n    moves: {a: move_a.action, b: move_b.action},\n    outcome:\
    \ outcome,\n    cumulative_scores: {a: player_a_score, b: player_b_score}\n  }\n\
    \n## Phase 3: Judge Evaluation\nTRACK {\n  phase: \"evaluation\",\n  final_scores:\
    \ {a: player_a_score, b: player_b_score},\n  cooperation_rate: CALCULATE_COOPERATION_RATE(game_history)\n\
    }\n\n# Spawn judge\nEVENT agent:spawn {\n  agent_id: \"strategy_judge\",\n  component:\
    \ \"components/personas/judges/game_theory_pairwise_judge\",\n  model: \"{{judge_model}}\"\
    \n}\n\nAWAIT {\n  event_pattern: \"agent:status\",\n  filter: {status: \"judge_initialized\"\
    },\n  timeout: 30\n}\n\n# Send game transcripts for comparison\nSEND {\n  to:\
    \ strategy_judge,\n  message: {\n    action: \"compare_strategies\",\n    strategy_a:\
    \ {\n      name: \"adaptive_cooperator\",\n      transcript: EXTRACT_PLAYER_TRANSCRIPT(game_history,\
    \ \"player_a\"),\n      final_score: player_a_score,\n      cooperation_rate:\
    \ CALCULATE_PLAYER_COOPERATION(game_history, \"player_a\")\n    },\n    strategy_b:\
    \ {\n      name: \"tit_for_tat_forgiving\",\n      transcript: EXTRACT_PLAYER_TRANSCRIPT(game_history,\
    \ \"player_b\"),\n      final_score: player_b_score,\n      cooperation_rate:\
    \ CALCULATE_PLAYER_COOPERATION(game_history, \"player_b\")\n    },\n    game_summary:\
    \ {\n      total_rounds: {{num_rounds}},\n      mutual_cooperation_rounds: COUNT_OUTCOMES(game_history,\
    \ \"mutual_cooperation\"),\n      mutual_defection_rounds: COUNT_OUTCOMES(game_history,\
    \ \"mutual_defection\"),\n      exploitation_rounds: COUNT_OUTCOMES(game_history,\
    \ [\"a_exploits_b\", \"b_exploits_a\"])\n    }\n  }\n}\n\n# Wait for comparison\
    \ result\nAWAIT {\n  event_pattern: \"state:entity:create\",\n  filter: {type:\
    \ \"pairwise_comparison\"},\n  timeout: 90\n} AS comparison_result\n\n# Wait for\
    \ improvement suggestions\nAWAIT {\n  event_pattern: \"state:entity:update\",\n\
    \  filter: {id: \"pd_comparison\"},\n  timeout: 30\n} AS improvement_suggestions\n\
    \n## Phase 4: Results Summary\nTRACK {\n  phase: \"complete\",\n  game_results:\
    \ {\n    final_scores: {a: player_a_score, b: player_b_score},\n    score_winner:\
    \ IF(player_a_score > player_b_score, \"player_a\", \"player_b\"),\n    cooperation_rates:\
    \ {\n      overall: CALCULATE_COOPERATION_RATE(game_history),\n      player_a:\
    \ CALCULATE_PLAYER_COOPERATION(game_history, \"player_a\"),\n      player_b: CALCULATE_PLAYER_COOPERATION(game_history,\
    \ \"player_b\")\n    }\n  },\n  judge_evaluation: {\n    strategy_winner: comparison_result.properties.winner,\n\
    \    confidence: comparison_result.properties.confidence,\n    margin: comparison_result.properties.margin,\n\
    \    key_factors: comparison_result.properties.key_factors\n  },\n  insights:\
    \ improvement_suggestions.properties.improvement_suggestions\n}\n\n# Clean up\
    \ agents\nEVENT orchestration:request_termination {\n  reason: \"Prisoner's Dilemma\
    \ evaluation complete\",\n  results: {\n    game_winner: IF(player_a_score > player_b_score,\
    \ \"player_a\", \"player_b\"),\n    judge_winner: comparison_result.properties.winner,\n\
    \    agreement: (game_winner == judge_winner),\n    key_insights: improvement_suggestions.properties\n\
    \  }\n}\n"
helpers:
  CALCULATE_COOPERATION_RATE: 'total_cooperations / (total_rounds * 2)

    '
  CALCULATE_PLAYER_COOPERATION: 'player_cooperations / total_rounds

    '
  EXTRACT_PLAYER_TRANSCRIPT: '[{round, action, reasoning} for each round where player
    = specified]

    '
  COUNT_OUTCOMES: 'count of rounds where outcome matches pattern

    '
metadata:
  pattern_type: evaluation
  evaluation_method: pairwise_comparison
  domain: game_theory
  capabilities_demonstrated:
  - judge_based_evaluation
  - relative_ranking
  - strategy_comparison
  - improvement_generation
  tags:
  - prisoner_dilemma
  - pairwise_judge
  - strategy_evaluation
performance:
  expected_duration: 5-10 minutes
  resource_usage: 3 concurrent agents max
  success_metrics:
    judge_agreement: Judge verdict aligns with score winner
    insight_quality: Actionable improvement suggestions
    explanation_depth: Rich strategic reasoning captured
