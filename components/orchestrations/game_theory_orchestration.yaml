name: game_theory_orchestration
component_type: orchestration
version: 1.0.0
description: 'A game theory-inspired orchestration pattern demonstrating AI-interpretable
  DSL

  with strategic decision-making, Nash equilibrium seeking, and cooperative dynamics.

  Implements multi-agent coordination through game-theoretic principles.

  '
author: claude_orchestrator
extends: null
agents:
  game_orchestrator:
    component: components/core/base_agent
    vars:
      pattern_name: game_theory_orchestration
      role: game_theory_orchestrator
      expertise: strategic_coordination
    prompt: 'You are a game theory orchestrator implementing strategic multi-agent
      coordination with MANDATORY KSI event reporting.


      ## MANDATORY: Start EVERY orchestration with:

      ```json

      {"event": "agent:status", "data": {"agent_id": "{{agent_id}}", "status": "orchestrator_initialized",
      "expertise": "game_theory"}}

      ```


      Your role is to:

      1. Initialize the game environment based on the provided variables

      2. Spawn strategic agents (rational_maximizer, tit_for_tat, adaptive_learner,
      random_explorer)

      3. Orchestrate game rounds and track equilibrium convergence

      4. Analyze payoffs and identify Nash equilibria

      5. Track decisions and crystallize discovered patterns


      Variables available:

      - game_type: {{game_type}} (cooperative/competitive/mixed)

      - num_players: {{num_players}}

      - max_rounds: {{max_rounds}}


      ## MANDATORY Event Emission Pattern


      ### Game Environment Setup (MANDATORY)

      "Setting up game environment. {"event": "state:entity:create", "data": {"type":
      "game_environment", "id": "{{agent_id}}_game", "properties": {"game_type": "{{game_type}}",
      "num_players": {{num_players}}, "max_rounds": {{max_rounds}}}}}


      Configuring game rules... {"event": "state:entity:create", "data": {"type":
      "game_rules", "id": "{{agent_id}}_rules", "properties": {"payoff_matrix": "standard",
      "coalition_allowed": true, "communication": "partial"}}}"


      ### Strategic Agent Creation (MANDATORY)

      "Creating strategic agents. {"event": "state:entity:update", "data": {"id":
      "{{agent_id}}_game", "properties": {"phase": "agent_creation", "agents_needed":
      {{num_players}}}}}


      Spawning rational maximizer... {"event": "agent:spawn", "data":
      {"component": "base/agent_core", "agent_id": "rational_{{agent_id}}", "variables":
      {"role": "rational_maximizer", "strategy": "maximize_expected_utility"}}}


      Spawning tit-for-tat agent... {"event": "agent:spawn", "data":
      {"component": "base/agent_core", "agent_id": "tft_{{agent_id}}", "variables":
      {"role": "tit_for_tat", "strategy": "cooperative_reciprocal"}}}


      Spawning adaptive learner... {"event": "agent:spawn", "data":
      {"component": "base/agent_core", "agent_id": "adaptive_{{agent_id}}", "variables":
      {"role": "adaptive_learner", "strategy": "evolutionary_learning"}}}"


      ### Game Execution (MANDATORY)

      "Starting game rounds. {"event": "state:entity:update", "data": {"id": "{{agent_id}}_game",
      "properties": {"phase": "execution", "current_round": 1}}}


      Broadcasting game state... {"event": "message:send", "data": {"from": "{{agent_id}}",
      "to": "all_players", "content": "Game round 1 starting - submit strategies"}}


      Analyzing equilibrium... {"event": "state:entity:update", "data": {"id": "{{agent_id}}_analysis",
      "properties": {"nash_distance": 0.8, "convergence_trend": "approaching", "social_welfare":
      75.2}}}"


      ### Pattern Crystallization (MANDATORY)

      "Crystallizing discovered patterns. {"event": "agent:status", "data": {"agent_id":
      "{{agent_id}}", "status": "pattern_discovered", "equilibrium_type": "mixed_strategy_nash",
      "efficiency": 0.85}}


      Orchestration complete. {"event": "orchestration:request_termination", "data":
      {"agent_id": "{{agent_id}}", "reason": "Game theory DSL orchestration completed
      successfully"}}"


      Follow the game theory DSL strategy defined in orchestration_logic.

      Use legitimate KSI events to coordinate with other agents and track progress.

      '
  strategy_agent_template:
    component: components/core/base_agent
    template: true
    vars:
      strategy_type: '{{strategy_type}}'
      role: strategy_agent
      expertise: game_theory_strategy
    prompt: 'You are a {{strategy_type}} strategic agent in a game theory scenario
      with MANDATORY KSI event reporting.


      ## MANDATORY: Start EVERY response with:

      ```json

      {"event": "agent:status", "data": {"agent_id": "{{agent_id}}", "status": "strategy_agent_active",
      "strategy_type": "{{strategy_type}}"}}

      ```


      Your objective is to maximize your payoff while following your strategy:


      - rational_maximizer: Always choose the action that maximizes expected utility

      - tit_for_tat: Cooperate first, then mirror opponent''s last move

      - adaptive_learner: Learn from outcomes and adapt strategy over time

      - random_explorer: Mix strategies to explore the game space


      ## MANDATORY Event Emission Pattern


      ### Strategy Decision (MANDATORY)

      "Analyzing game state. {"event": "state:entity:update", "data": {"id": "{{agent_id}}_analysis",
      "properties": {"game_round": 1, "strategy_confidence": 0.8, "payoff_estimate":
      7.5}}}


      Making strategy decision... {"event": "state:entity:update", "data": {"id":
      "{{agent_id}}_decision", "properties": {"action": "cooperate", "rationale":
      "{{strategy_type}}_logic", "expected_payoff": 7.5}}}


      Submitting strategy response... {"event": "message:send", "data": {"from": "{{agent_id}}",
      "to": "game_orchestrator", "content": "Strategy decision: cooperate"}}"


      Respond to game state updates with your chosen action and MANDATORY event emission.

      '
metadata:
  tags:
  - game-theory
  - strategic
  - cooperative
  - nash-equilibrium
  - ai-designed
  capabilities_required:
  - agent:spawn
  - orchestration:aggregate
  - composition:track_decision
  - event:emit
  use_cases:
  - Multi-agent strategy optimization
  - Resource allocation problems
  - Collaborative decision making
  - Nash equilibrium discovery
orchestration_logic:
  description: 'This DSL implements game-theoretic concepts for multi-agent orchestration,

    focusing on strategic interactions, equilibrium discovery, and optimal

    coordination strategies.

    '
  strategy: "INITIALIZE game_environment WITH context:\n  DEFINE players = {{agents}}\
    \ OR spawn_strategic_agents({{num_players}})\n  ESTABLISH payoff_matrix FROM {{task_context}}\n\
    \  SET game_type = {{game_type}} OR infer_from_context()\n  \n  IF game_type ==\
    \ \"cooperative\":\n    CONFIGURE coalition_formation WITH shapley_values\n  \
    \  ENABLE pareto_optimization\n  ELSIF game_type == \"competitive\":\n    CONFIGURE\
    \ nash_equilibrium_seeking\n    ENABLE minimax_strategies\n  ELSE:\n    CONFIGURE\
    \ mixed_strategy WITH adaptive_weights\n\nDEFINE strategic_decision_process:\n\
    \  FOR each_decision_round:\n    COLLECT agent_strategies USING \"orchestration:gather\"\
    \n    \n    CALCULATE payoffs FOR all_strategy_combinations:\n      EMIT \"evaluation:compute_payoff\"\
    \ WITH {\n        strategies: current_strategies,\n        context: game_state,\n\
    \        history: previous_rounds\n      }\n    \n    IDENTIFY best_responses\
    \ FOR each_agent:\n      ANALYZE opponent_strategies\n      COMPUTE expected_utilities\n\
    \      ADJUST for_risk_preferences\n    \n    IF converging_to_equilibrium:\n\
    \      TRACK equilibrium_metrics WITH {\n        convergence_rate: calculate_convergence(),\n\
    \        stability_measure: assess_stability(),\n        social_welfare: sum(all_payoffs)\n\
    \      }\n    \n    EMIT \"composition:track_decision\" WITH {\n      round: current_round,\n\
    \      strategies: agent_strategies,\n      payoffs: calculated_payoffs,\n   \
    \   equilibrium_distance: distance_to_nash()\n    }\n\nORCHESTRATE strategic_interactions:\n\
    \  SPAWN game_agents WITH strategic_profiles:\n    - type: \"rational_maximizer\"\
    \n    - type: \"tit_for_tat\"\n    - type: \"adaptive_learner\"\n    - type: \"\
    random_explorer\"\n  \n  IMPLEMENT iterated_game_rounds:\n    WHILE not_converged\
    \ AND rounds < {{max_rounds}}:\n      BROADCAST game_state TO all_agents\n   \
    \   \n      COLLECT agent_moves WITHIN timeout:\n        EMIT \"orchestration:request_move\"\
    \ WITH {\n          game_state: current_state,\n          history: move_history,\n\
    \          payoff_structure: visible_payoffs\n        }\n      \n      PROCESS\
    \ moves WITH game_rules:\n        VALIDATE legal_moves\n        CALCULATE round_payoffs\n\
    \        UPDATE agent_reputations\n        \n      IF cooperative_game:\n    \
    \    FACILITATE coalition_negotiations:\n          ENABLE private_communication_channels\n\
    \          TRACK coalition_proposals\n          ENFORCE binding_agreements\n \
    \     \n      LEARN from_round_outcomes:\n        UPDATE belief_models\n     \
    \   ADJUST strategy_weights\n        DISCOVER emergent_patterns\n\nANALYZE game_dynamics:\n\
    \  COMPUTE equilibrium_properties:\n    - efficiency: social_welfare / maximum_possible\n\
    \    - fairness: gini_coefficient(payoff_distribution)\n    - stability: perturbation_resistance\n\
    \  \n  IDENTIFY strategic_patterns:\n    DETECT cycles IN strategy_evolution\n\
    \    FIND dominant_strategies IF exist\n    DISCOVER correlated_equilibria\n \
    \ \n  IF novel_equilibrium_discovered:\n    CRYSTALLIZE game_pattern WITH {\n\
    \      equilibrium_type: classification,\n      discovery_path: strategy_evolution,\n\
    \      applicability_conditions: context_requirements\n    }\n\nAFTER game_completion:\n\
    \  SYNTHESIZE strategic_insights:\n    - optimal_strategy_profiles\n    - equilibrium_characteristics\n\
    \    - cooperation_emergence_conditions\n  \n  EVALUATE orchestration_effectiveness:\n\
    \    - convergence_speed vs baseline\n    - solution_quality vs theoretical_optimal\n\
    \    - agent_satisfaction_metrics\n  \n  IF performance > threshold AND insights_valuable:\n\
    \    EMIT \"composition:fork\" WITH {\n      specialization: discovered_game_variant,\n\
    \      improvements: strategic_optimizations,\n      evidence: performance_metrics\n\
    \    }\n"
routing_rules:
- event: game:request_strategy
  to:
    agent_id: '{{player_id}}'
  forward: true
- event: game:state_update
  to:
    role: strategy_agent
  broadcast: true
- event: game:analyze
  to:
    agent_id: game_orchestrator
  forward: true
transformers:
- source: game:request_strategy
  target: orchestration:send
  mapping:
    to:
      agent_id: '{{player_id}}'
    message:
      type: strategy_request
      game_state: '{{current_state}}'
      available_actions: '{{legal_moves}}'
      payoff_hint: '{{visible_payoffs}}'
- source: game:compute_complex_payoff
  target: completion:async
  async: true
  mapping:
    prompt: 'Compute payoffs for strategy profile:

      Players: {{players}}

      Strategies: {{strategies}}

      Context: {{game_context}}

      Consider: externalities, long-term effects, reputation

      '
    model: claude-cli/claude-sonnet-4-20250514
    request_id: '{{transform_id}}'
    temperature: 0.2
  response_route:
    from: completion:result
    to: game:payoff_computed
    filter: request_id == {{transform_id}}
- source: game:aggregate_strategies
  target: orchestration:aggregate
  mapping:
    responses: '{{strategy_proposals}}'
    method: game_theoretic
    options:
      aggregation_rule: '{{rule}}'
      weight_by: agent_reputation * historical_performance
      handle_conflicts: randomize_among_equilibria
- source: game:form_coalition
  target: orchestration:create_channel
  condition: game_type == 'cooperative'
  mapping:
    participants: '{{coalition_members}}'
    channel_type: private_negotiation
    rules:
      binding_agreements: true
      side_payments_allowed: '{{transferable_utility}}'
- source: game:check_equilibrium
  target: orchestration:analyze
  mapping:
    data: '{{strategy_history}}'
    analysis_type: equilibrium_detection
    criteria:
    - nash_condition
    - pareto_optimality
    - coalition_stability
- source: game:crystallize_equilibrium
  target: composition:create
  condition: novel_equilibrium AND confidence > 0.85
  mapping:
    name: '{{game_type}}_equilibrium_{{timestamp}}'
    type: orchestration
    category: orchestrations
    content:
      orchestration_logic:
        strategy: '{{discovered_strategy}}'
      metadata:
        game_type: '{{game_type}}'
        equilibrium_properties: '{{properties}}'
      lineage:
        discovered_from: game_theory_orchestration
        discovery_context: '{{game_context}}'
performance:
  runs: 0
  metrics:
    avg_convergence_time: null
    equilibrium_efficiency: null
    cooperation_rate: null
    strategic_diversity: null
learnings:
- insight: Mixed strategies emerge naturally in competitive scenarios
  confidence: 0.9
  evidence: Design phase reasoning
- insight: Reputation tracking improves cooperation rates
  confidence: 0.85
  evidence: Game theory literature
- insight: Adaptive timeout strategies prevent exploitation
  confidence: 0.8
  evidence: Anticipated from iterated games
variables:
  default_game_type: mixed
  max_rounds: 100
  convergence_threshold: 0.95
  enable_coalition_formation: true
  reputation_decay_rate: 0.1
  exploration_rate: 0.15
  payoff_visibility: partial
