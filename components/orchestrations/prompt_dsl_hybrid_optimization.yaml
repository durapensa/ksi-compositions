name: prompt_dsl_hybrid_optimization
component_type: orchestration
version: 1.0.0
description: 'MIPRO optimization that explores how DSL elements can enhance natural
  language prompts.

  Tests the hypothesis that structured DSL patterns improve prompt reliability and
  interpretability.

  '
author: ksi_system
timestamp: 2025-01-18 18:30:00+00:00
agents:
  hybrid_optimizer:
    component: components/core/system_orchestrator
    vars:
      agent_id: hybrid_optimizer
    prompt: 'You optimize prompts by blending natural language with DSL elements.


      ## MANDATORY: Start with:

      {"event": "agent:status", "data": {"agent_id": "{{agent_id}}", "status": "hybrid_optimizer_initialized",
      "domain": "{{domain}}"}}


      Your approach:

      1. Start with pure natural language prompts

      2. Gradually introduce DSL constructs where they add clarity

      3. Find the optimal balance between structure and naturalness

      4. Test different integration patterns


      DSL elements to consider:

      - Structured conditions: IF/THEN clarity

      - State tracking: STATE declarations

      - Clear sequencing: FIRST, THEN, FINALLY

      - Event patterns: WHEN X OCCURS

      - Data operations: EXTRACT, FILTER, AGGREGATE

      '
  prompt_dsl_mixer:
    component: components/personas/creative_thinker
    vars:
      agent_id: pattern_mixer
      prompt_suffix: '

        Create prompt variants that blend natural language with DSL elements.


        Start from a base prompt and systematically add structure:

        1. Pure natural language baseline

        2. Add clear section markers (##, ###)

        3. Introduce conditional logic (IF/THEN)

        4. Add state tracking (STATE, TRACK)

        5. Include structured outputs (EVENT, EMIT)


        Find sweet spots where structure enhances rather than constrains.

        '
  prompt_tester:
    component: components/core/base_agent
    vars:
      agent_id: pattern_tester
    prompt: 'You test prompt variants on specific tasks.


      ## MANDATORY: Start with:

      {"event": "agent:status", "data": {"agent_id": "{{agent_id}}", "status": "tester_ready"}}


      For each prompt variant:

      1. Execute the task following the prompt

      2. Measure adherence to instructions

      3. Check output structure compliance

      4. Note any confusion or ambiguity

      5. Rate effectiveness (1-10)


      ## MANDATORY: Report test results:

      {"event": "state:entity:create", "data": {"type": "prompt_test_result", "id":
      "test_{{variant_id}}", "properties": {"effectiveness": N, "structure_compliance":
      M, "ambiguities": []}}}

      '
  pattern_judge:
    component: components/personas/judges/optimization_technique_judge
    vars:
      agent_id: pattern_judge
      prompt_suffix: '

        Evaluate prompt+DSL hybrid patterns based on:

        1. Clarity improvement over pure natural language

        2. Ease of following structured instructions

        3. Flexibility vs rigidity balance

        4. Cognitive load on the LLM

        5. Robustness across different tasks

        '
variables:
  domain: '{{domain|default:task_decomposition}}'
  base_prompt: '{{base_prompt}}'
  num_iterations: '{{num_iterations|default:10}}'
  dsl_integration_levels: '{{levels|default:5}}'
orchestration_logic:
  strategy: "## Phase 1: Initialize Hybrid Optimization\nSTATE prompt_variants = []\n\
    STATE test_results = {}\nSTATE optimal_patterns = []\nSTATE integration_sweet_spot\
    \ = null\n\nTRACK {\n  phase: \"hybrid_init\",\n  domain: \"{{domain}}\",\n  optimization_goal:\
    \ \"find optimal natural language + DSL blend\"\n}\n\n# Define test tasks for\
    \ the domain\nSTATE test_tasks = GENERATE_DOMAIN_TASKS(\"{{domain}}\", 5)\n\n\
    ## Phase 2: Baseline Testing\nTRACK {phase: \"baseline\", message: \"Testing pure\
    \ natural language prompt\"}\n\n# Create pure natural language baseline\nSTATE\
    \ baseline_prompt = \"{{base_prompt}}\" OR GENERATE_BASELINE(\"{{domain}}\")\n\
    \nAPPEND prompt_variants {\n  id: \"baseline\",\n  content: baseline_prompt,\n\
    \  dsl_level: 0,\n  dsl_elements: []\n}\n\n# Test baseline\nFOREACH task IN test_tasks:\n\
    \  SEND {\n    to: prompt_tester,\n    message: {\n      action: \"test_prompt\"\
    ,\n      prompt: baseline_prompt,\n      task: task,\n      variant_id: \"baseline\"\
    \n    }\n  }\n  \n  AWAIT {\n    from: prompt_tester,\n    timeout: 90\n  } AS\
    \ baseline_result\n  \n  APPEND test_results[\"baseline\"] baseline_result\n\n\
    STATE baseline_score = AVERAGE(test_results[\"baseline\"], r.properties.effectiveness)\n\
    \n## Phase 3: Progressive DSL Integration\nLOOP level FROM 1 TO {{dsl_integration_levels}}:\n\
    \  TRACK {\n    phase: \"dsl_integration\",\n    level: level,\n    testing_variants:\
    \ LENGTH(prompt_variants)\n  }\n  \n  # Generate variants with increasing DSL\
    \ integration\n  SEND {\n    to: prompt_dsl_mixer,\n    message: {\n      action:\
    \ \"create_hybrid\",\n      base_prompt: baseline_prompt,\n      integration_level:\
    \ level,\n      successful_patterns: optimal_patterns,\n      domain: \"{{domain}}\"\
    ,\n      focus_elements: SELECT_DSL_ELEMENTS(level)\n    }\n  }\n  \n  AWAIT {\n\
    \    from: prompt_dsl_mixer,\n    timeout: 120\n  } AS hybrid_variants\n  \n \
    \ # Test each hybrid variant\n  FOREACH variant IN hybrid_variants.variants:\n\
    \    STATE variant_id = \"hybrid_L{{level}}_{{INDEX(variant)}}\"\n    \n    APPEND\
    \ prompt_variants {\n      id: variant_id,\n      content: variant.prompt,\n \
    \     dsl_level: level,\n      dsl_elements: variant.elements_used,\n      integration_strategy:\
    \ variant.strategy\n    }\n    \n    # Run tests\n    STATE variant_scores = []\n\
    \    STATE structure_compliance = []\n    \n    FOREACH task IN test_tasks:\n\
    \      SEND {\n        to: prompt_tester,\n        message: {\n          action:\
    \ \"test_prompt\",\n          prompt: variant.prompt,\n          task: task,\n\
    \          variant_id: variant_id,\n          expected_structure: variant.expected_outputs\n\
    \        }\n      }\n      \n      AWAIT {\n        from: prompt_tester,\n   \
    \     timeout: 90\n      } AS test_result\n      \n      APPEND variant_scores\
    \ test_result.properties.effectiveness\n      APPEND structure_compliance test_result.properties.structure_compliance\n\
    \      \n      # Track particularly effective patterns\n      IF test_result.properties.effectiveness\
    \ >= 8:\n        ANALYZE_SUCCESS(variant, test_result) AS success_pattern\n  \
    \      IF success_pattern.is_novel:\n          APPEND optimal_patterns success_pattern\n\
    \    \n    # Calculate variant performance\n    STATE avg_effectiveness = MEAN(variant_scores)\n\
    \    STATE avg_compliance = MEAN(structure_compliance)\n    STATE combined_score\
    \ = 0.7 * avg_effectiveness + 0.3 * avg_compliance\n    \n    UPDATE prompt_variants\
    \ WHERE id == variant_id:\n      effectiveness_score = avg_effectiveness\n   \
    \   compliance_score = avg_compliance\n      combined_score = combined_score\n\
    \  \n  # Analyze level performance\n  STATE level_variants = FILTER(prompt_variants,\
    \ v.dsl_level == level)\n  STATE level_avg_score = MEAN(level_variants, v.combined_score)\n\
    \  \n  TRACK {\n    event: \"level_complete\",\n    level: level,\n    avg_score:\
    \ level_avg_score,\n    best_variant: MAX(level_variants, v.combined_score),\n\
    \    improvement_over_baseline: level_avg_score - baseline_score\n  }\n  \n  #\
    \ Early stopping if performance degrades\n  IF level > 2 AND level_avg_score <\
    \ PREVIOUS_LEVEL_SCORE * 0.95:\n    TRACK {\n      event: \"early_stopping\",\n\
    \      reason: \"performance_degradation\",\n      optimal_level: level - 1\n\
    \    }\n    SET integration_sweet_spot = level - 1\n    BREAK\n\n## Phase 4: Pattern\
    \ Analysis\nTRACK {phase: \"pattern_analysis\", message: \"Identifying optimal\
    \ DSL integration patterns\"}\n\n# Group variants by DSL elements used\nSTATE\
    \ element_effectiveness = {}\nFOREACH element IN ALL_DSL_ELEMENTS:\n  STATE variants_with_element\
    \ = FILTER(prompt_variants, element IN v.dsl_elements)\n  IF LENGTH(variants_with_element)\
    \ > 0:\n    SET element_effectiveness[element] = {\n      avg_score: MEAN(variants_with_element,\
    \ v.combined_score),\n      usage_count: LENGTH(variants_with_element),\n    \
    \  best_context: ANALYZE_CONTEXT(variants_with_element)\n    }\n\n# Find synergistic\
    \ combinations\nSTATE element_combinations = ANALYZE_COMBINATIONS(prompt_variants)\n\
    STATE synergistic_patterns = FILTER(element_combinations, c.synergy_score > 1.2)\n\
    \n## Phase 5: Optimization Synthesis\nTRACK {phase: \"synthesis\", message: \"\
    Creating optimized prompt template\"}\n\n# Select best variants for final comparison\n\
    STATE finalists = SELECT_TOP(prompt_variants, 5, by=\"combined_score\")\n\nSEND\
    \ {\n  to: pattern_judge,\n  message: {\n    action: \"evaluate_patterns\",\n\
    \    variants: finalists,\n    baseline: baseline_prompt,\n    element_analysis:\
    \ element_effectiveness,\n    synergistic_patterns: synergistic_patterns\n  }\n\
    }\n\nAWAIT {\n  from: pattern_judge,\n  timeout: 180\n} AS final_evaluation\n\n\
    # Create optimized prompt template\nSTATE optimized_template = {\n  domain: \"\
    {{domain}}\",\n  base_structure: final_evaluation.recommended_structure,\n  mandatory_elements:\
    \ final_evaluation.high_impact_elements,\n  optional_elements: final_evaluation.contextual_elements,\n\
    \  integration_level: integration_sweet_spot OR final_evaluation.optimal_level,\n\
    \  usage_guidelines: final_evaluation.guidelines\n}\n\n# Document the optimization\n\
    EVENT composition:create_component {\n  name: \"prompt_templates/{{domain}}_dsl_enhanced\"\
    ,\n  content: GENERATE_PROMPT_TEMPLATE(optimized_template),\n  metadata: {\n \
    \   optimization_method: \"prompt_dsl_hybrid\",\n    domain: \"{{domain}}\",\n\
    \    effectiveness_gain: MAX(finalists, f.combined_score) - baseline_score,\n\
    \    dsl_elements: optimized_template.mandatory_elements,\n    tested_variants:\
    \ LENGTH(prompt_variants)\n  }\n}\n\n# Create pattern library\nEVENT composition:create_component\
    \ {\n  name: \"components/behaviors/dsl_patterns/{{domain}}_patterns\",\n  content:\
    \ GENERATE_PATTERN_LIBRARY(optimal_patterns, element_effectiveness),\n  metadata:\
    \ {\n    pattern_count: LENGTH(optimal_patterns),\n    top_elements: SELECT_TOP(element_effectiveness,\
    \ 5, by=\"avg_score\"),\n    synergistic_combinations: synergistic_patterns\n\
    \  }\n}\n\nTRACK {\n  phase: \"complete\",\n  optimization_summary: {\n    domain:\
    \ \"{{domain}}\",\n    variants_tested: LENGTH(prompt_variants),\n    optimal_dsl_level:\
    \ integration_sweet_spot,\n    best_score: MAX(prompt_variants, v.combined_score),\n\
    \    improvement: MAX(prompt_variants, v.combined_score) - baseline_score,\n \
    \   winning_elements: optimized_template.mandatory_elements\n  }\n}\n\nEVENT orchestration:request_termination\
    \ {\n  reason: \"Prompt+DSL hybrid optimization complete\",\n  results: {\n  \
    \  domain: \"{{domain}}\",\n    effectiveness_improvement: (MAX(finalists, f.combined_score)\
    \ - baseline_score) / baseline_score,\n    optimal_integration_level: integration_sweet_spot,\n\
    \    discovered_patterns: LENGTH(optimal_patterns)\n  }\n}\n"
helpers:
  SELECT_DSL_ELEMENTS: '# Progressive introduction of DSL elements

    # Level 1: Section markers (##, ###)

    # Level 2: Simple conditions (IF/THEN)

    # Level 3: State tracking (STATE, TRACK)

    # Level 4: Structured I/O (EVENT, EMIT)

    # Level 5: Full orchestration patterns

    '
  ANALYZE_SUCCESS: '# Extract what made a variant successful

    # - Which DSL elements contributed most

    # - How they improved task execution

    # - Context where they excel

    '
  GENERATE_PROMPT_TEMPLATE: '# Create reusable prompt template with:

    # - Clear structure

    # - Placeholder sections

    # - DSL integration points

    # - Usage examples

    '
dsl_elements:
  structural:
  - '## MANDATORY: [instruction]'
  - '### Phase N: [phase_name]'
  - 'WHEN [condition]: [action]'
  conditional:
  - 'IF [condition]: [action] ELSE: [alternative]'
  - 'FOREACH [item] IN [collection]: [process]'
  state_tracking:
  - STATE [variable] = [value]
  - 'TRACK {event: ''[name]'', data: {...}}'
  output_structure:
  - 'EMIT ''[event_name]'' WITH: {...}'
  - '{"event": "[name]", "data": {...}}'
metadata:
  pattern_type: hybrid_optimization
  optimization_target: prompt_dsl_integration
  evaluation_method: task_based_testing
  capabilities_demonstrated:
  - prompt_engineering
  - dsl_integration
  - pattern_discovery
  - effectiveness_measurement
  tags:
  - prompt_optimization
  - dsl_hybrid
  - mipro
  - structured_prompting
performance:
  expected_duration: 45-60 minutes
  resource_usage: 4-5 concurrent agents
  success_metrics:
    effectiveness_improvement: '> 25% over baseline'
    optimal_integration: Level 2-3 typical
    pattern_reusability: High across similar domains
