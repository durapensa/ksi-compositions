name: automated_optimization_tournament
component_type: orchestration
version: 1.0.0
description: Automated tournament with optimization and evaluation
author: ksi

variables:
  component_to_optimize: "personas/data_analyst"
  optimization_framework: "dspy"
  num_variants: 3
  task_prompt: "Analyze this quarterly revenue data: Q1: $1.2M, Q2: $1.5M, Q3: $1.3M, Q4: $1.8M"

agents:
  optimizer:
    component: "components/core/base_agent"
    prompt: |
      You are an optimization coordinator.
      Trigger optimization of {{component_to_optimize}} using {{optimization_framework}}.
      Create {{num_variants}} variants for tournament testing.
    
  variant_1:
    component: "components/{{component_to_optimize}}"
    vars:
      variant: "original"
    
  variant_2: 
    component: "components/{{component_to_optimize}}"
    vars:
      variant: "optimized_v1"
      
  variant_3:
    component: "components/{{component_to_optimize}}" 
    vars:
      variant: "optimized_v2"
    
  judge:
    component: "components/evaluations/llm_judge"
    vars:
      evaluation_type: "tournament"

routing:
  rules:
    # Variants send responses to judge
    - pattern: "agent:response"
      from: "variant_*"
      to: "judge"
    
    # Judge sends evaluation to optimizer
    - pattern: "evaluation:complete"
      from: "judge"
      to: "optimizer"
    
    # Optimizer triggers optimization
    - pattern: "optimization:request"
      from: "optimizer"
      to: "optimization_service"

coordination:
  turn_taking:
    mode: "phased"
    phases:
      - name: "initial_optimization"
        description: "Optimize base component"
        agents:
          - optimizer: |
              Create optimized versions of {{component_to_optimize}}:
              1. Use MIPRO to optimize instruction clarity
              2. Create 2 distinct variants with different approaches
              3. Save as optimized_v1 and optimized_v2
      
      - name: "tournament_round"
        description: "Test all variants"
        agents:
          - variant_1: "{{task_prompt}}"
          - variant_2: "{{task_prompt}}"
          - variant_3: "{{task_prompt}}"
      
      - name: "evaluation"
        description: "Judge evaluates results"
        agents:
          - judge: |
              Evaluate the three analyst variants based on:
              - Accuracy and completeness of analysis
              - Clarity of insights
              - Cost-effectiveness
              - Processing efficiency
              
              Determine the winner and provide optimization recommendations.
      
      - name: "apply_learning"
        description: "Apply tournament learnings"
        agents:
          - optimizer: |
              Based on the evaluation results:
              1. Identify the winning approach
              2. Create a final optimized version incorporating best elements
              3. Document optimization insights for future use
  
  termination:
    conditions:
      - event: "optimization:complete"
      - timeout: 600

metadata:
  tags: ["tournament", "optimization", "automated", "evaluation"]
  optimization_config:
    frameworks: ["mipro", "simba"]
    metrics: ["accuracy", "efficiency", "cost"]