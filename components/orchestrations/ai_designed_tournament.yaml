name: ai_designed_tournament
component_type: orchestration
version: 1.0.0
description: |
  A tournament pattern with DSL designed by AI for AI orchestrators.
  Demonstrates compositional intelligence through adaptive strategies,
  context-aware decision making, and emergent coordination patterns.
author: claude_orchestrator
extends: null

metadata:
  tags:
    - tournament
    - ai-designed
    - compositional
    - adaptive
    - context-aware
  capabilities_required:
    - evaluation:prompt
    - agent:spawn
    - orchestration:aggregate
    - composition:track_decision
  use_cases:
    - AI capability assessment
    - Prompt optimization tournaments
    - Model comparison studies
    - Emergent strategy discovery

# Natural language DSL designed for AI interpretation
orchestration_logic:
  description: |
    This DSL is designed to be interpreted by AI orchestrators, focusing on
    intent and context rather than rigid syntax. The language blends declarative
    goals with adaptive strategies.
  
  strategy: |
    INITIALIZE tournament WITH context:
      ASSESS participants.capabilities USING "composition:discover"
      ANALYZE task.complexity AND participant.diversity
      SYNTHESIZE optimal_format FROM historical_patterns
      
      IF high_capability_variance OR complex_task:
        CONFIGURE adaptive_matching WITH swiss_pairing
        ENABLE dynamic_complexity_adjustment
      ELSE:
        CONFIGURE round_robin WITH parallel_execution
    
    DURING each_round:
      OBSERVE performance_metrics IN_REALTIME
      MAINTAIN context_window OF recent_interactions
      
      WHEN performance_anomaly_detected:
        INTROSPECT root_cause USING "orchestration:analyze"
        ADAPT strategy BASED_ON analysis.insights
        EMIT "composition:track_decision" WITH {
          decision: strategy_adaptation,
          reasoning: analysis.insights,
          confidence: self.confidence_score
        }
      
      IF consensus_forming AND rounds_remaining > 2:
        ACCELERATE convergence BY:
          - INCREASING test_discriminators
          - FOCUSING on_boundary_cases
          - REDUCING redundant_comparisons
      
      CONTINUOUSLY:
        BALANCE exploration VS exploitation
        OPTIMIZE for_signal NOT noise
        LEARN from_each_interaction
    
    ORCHESTRATE parallel_evaluations:
      SPAWN evaluator_agents WITH diverse_perspectives
      DISTRIBUTE tests USING capability_aware_routing
      
      FOR each_evaluation:
        PROVIDE minimal_sufficient_context
        ALLOW emergent_evaluation_criteria
        CAPTURE reasoning_traces
      
      AGGREGATE results USING "orchestration:aggregate" WITH {
        method: "weighted_consensus",
        weights: DERIVE_FROM agent.track_record,
        confidence_threshold: ADAPTIVE_BASED_ON variance
      }
    
    AFTER tournament_completion:
      SYNTHESIZE learnings FROM all_decisions
      IDENTIFY emergent_patterns IN strategy_adaptations
      
      IF performance > baseline * 1.2:
        CRYSTALLIZE successful_patterns INTO new_composition
        SHARE insights WITH pattern_ecosystem
      
      REFLECT on_orchestration_effectiveness:
        - What strategies emerged naturally?
        - Which adaptations improved outcomes?
        - How did context influence decisions?
      
      EMIT "composition:fork" IF confidence > 0.85 WITH {
        improvements: discovered_optimizations,
        rationale: performance_analysis
      }

# Event transformers for AI-designed vocabulary
transformers:
  # Transform high-level assessment into discovery
  - source: "tournament:assess_capabilities"
    target: "composition:discover"
    mapping:
      type: "profile"
      metadata_filter:
        capabilities: "{{required_capabilities}}"
      limit: 20
  
  # Async pattern analysis with context
  - source: "tournament:analyze_performance"
    target: "completion:async"
    async: true
    mapping:
      prompt: |
        Analyze tournament performance anomaly:
        Context: {{context_window}}
        Metrics: {{performance_metrics}}
        Identify root causes and suggest adaptations.
      model: "claude-cli/claude-sonnet-4-20250514"
      request_id: "{{transform_id}}"
      temperature: 0.3
    response_route:
      from: "completion:result"
      to: "tournament:analysis_complete"
      filter: "request_id == {{transform_id}}"
  
  # Conditional strategy adaptation
  - source: "tournament:adapt_strategy"
    target: "orchestration:broadcast"
    condition: "confidence > 0.7"
    mapping:
      criteria:
        role: "evaluator"
      message:
        type: "strategy_update"
        adaptation: "{{strategy_change}}"
        rationale: "{{reasoning}}"
  
  # Smart test distribution
  - source: "tournament:distribute_tests"
    target: "orchestration:route_task"
    mapping:
      task: "{{test_batch}}"
      routing_strategy: "capability_match"
      criteria:
        - "agent.capabilities CONTAINS {{required_capability}}"
        - "agent.workload < {{max_concurrent}}"
      fallback: "round_robin"
  
  # Aggregate with context-aware weighting
  - source: "tournament:aggregate_results"
    target: "orchestration:aggregate"
    mapping:
      responses: "{{evaluation_results}}"
      method: "weighted_consensus"
      options:
        weight_by: "agent_confidence * historical_accuracy"
        outlier_handling: "explain_then_consider"
        require_reasoning: true
  
  # Pattern crystallization
  - source: "tournament:crystallize_pattern"
    target: "composition:create"
    condition: "success_metrics.all_positive"
    mapping:
      name: "{{pattern_name}}"
      type: "orchestration"
      category: "orchestrations"
      content:
        orchestration_logic:
          strategy: "{{discovered_strategy}}"
        learnings: "{{pattern_insights}}"
        lineage:
          discovered_from: "ai_designed_tournament"
          discovery_context: "{{tournament_context}}"

# Performance tracking
performance:
  runs: 0
  metrics:
    adaptability_score: null
    convergence_rate: null
    decision_quality: null
    emergent_strategies: []

# Learnings section for pattern evolution
learnings:
  - insight: "AI orchestrators naturally develop context-aware strategies"
    confidence: 0.9
    evidence: "Initial design phase"
  - insight: "Compositional patterns emerge from simple primitives"
    confidence: 0.85
    evidence: "DSL structure demonstrates emergence"
  - insight: "Natural language DSL enables richer orchestration expression"
    confidence: 0.95
    evidence: "This pattern itself"

# Variables for runtime configuration
variables:
  default_complexity: "adaptive"
  min_confidence_threshold: 0.6
  enable_emergent_strategies: true
  context_window_size: 10
  pattern_crystallization_threshold: 0.85